---
title:  我的k8s之路2
date:   2020-08-01 11:08:00 +0800
categories: ["笔记"]
tags: ["k8s"]
keywords: ["k8s","kubectl","kubernetes","Pod","Deployments","ReplicaSet","Job","Cronjob","DaemonSet"]
description: "这是k8s的第二篇，但是已经时隔一年了。也不知道是k8s变化了，还是我之前的理解不够正确。不过我看了一眼，觉得上一篇写的一些内容，还是比较浅显易懂的，作为入门速览还不错。不过从这一篇开始，要好好抠细节了"
---


> 这是k8s的第二篇，但是已经时隔一年了。也不知道是k8s变化了，还是我之前的理解不够正确。
> 不过我看了一眼，觉得上一篇写的一些内容，还是比较浅显易懂的，作为入门速览还不错。不过从这一篇开始，要好好抠细节了。

## pod细节

修正上一篇文章说的pod推荐内部只包含单个docker用法。因为一个pod内部拥有多个docker，在很多场景下是非常不错的解决方案。

首先要说明一件事情，既然pod允许内部包含多个docker，而pod内的资源是可以互访的。没有手动挂在共享内容，是如何实现的呢？

pod内部就是一个小集群。通过infra-container来进行连接，也称之为sidecar设计模式。这样设计有一些有点。

![sidecar](/images/server/sidecar.png)

1. 单个image的更新，不会让整个pod重启。从而减少了开销。
2. 解决了pod内容器共享资源的问题。pod内的容器读取到的ip，mac地址等网络相关信息，其实都是infra-container的。
3. 方便拓展功能。例如我要加入一个nginx的转发。拿到一个/a的请求，可以在pod内新增一个用来代理的容器。把请求转发到应用容器的/b上。

## ReplicaSet和Deployments

这里一次讲2种kind:`ReplicaSet`,`Deployments`。

ReplicaSet是用来创建pod的，控制pod的数量、使用的pod版本。

Deployments是一个无状态的应用。他是用来控制各个版本的ReplicaSet。

通过上面来匹配呢？label。

![deployment](/images/server/deployment.png)

```bash
# 查看运行的pods
kubectl get pods
# 查看运行的replicasets
kubectl get replicasets
# 查看运行的deployments
kubectl get deployments
```

## 实例操作

### 简单示例

```yml
apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    name: myapp
spec:
  containers:
  - name: myapp
    image: nginx:1.11.1
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    ports:
      - containerPort: 80
```

在上面我们写了一个最简单的pod模板：
1. 一个名为myapp的无状态应用，同时通过label:myapp来匹配内容
2. 指定要用nginx:1.11.1镜像
3. 限制了使用的资源
4. 制定了要对集群暴露的端口

### 模板示例

模板示例不会把所有的参数都列出来。只是会把日常会用到的写出来。

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
    env: test
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  # 进入ready状态20秒后，才判断容器为available
  minReadySeconds: 20
  # 超过这个时间deployment还没有完全部署成功，就会失败！默认600
  # 必须必上面的值大。同时卡住后需要使用kubectl rollout undo回滚
  progressDeadlineSeconds: 100
  # 暂停部署deployment，这样可以通过set命令修改模板参数
  # paused: true
  strategy:
    rollingUpdate:
      # 默认25%的最大增长，100个pods，则升级时最多不能有125个
      # 我这里改成一次最多起5个pod
      maxSurge: 5
      # 最大不可用，100个pods，则最少要有75个随时能提供服务
      maxUnavailable: 25%
    type: RollingUpdate
  # 默认是10，保留的10个副本
  revisionHistoryLimit: 0
  template:
    metadata:
      labels:
        app: nginx
        env: test
    spec:
      containers:
        - name: nginx
          image: nginx:1.18
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 100m
              memory: 100Mi
          ports:
            - containerPort: 80
          # 存活检测
          livenessProbe:
            tcpSocket:
              port: 80
            # 初始化等待，例如jvm启动需要一定可预见的时间
            initialDelaySeconds: 5
            # 超时时间
            timeoutSeconds: 5
            # 失败以后，需要成功几次才能判定真的成功了
            successThreshold: 1
            # 失败的重试次数
            failureThreshold: 3
            # 检测间隔时间
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /
              port: 80
            initialDelaySeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 3
            periodSeconds: 10
          # 总是从服务器拉取image，会检验digest。所以其实也很快
          imagePullPolicy: Always
```

其实也没什么复杂的，也只有一点点细节设计：
1. 我们使用2个pod来提供服务。
2. 加上了一些常用参数，具体说明都在注释里。

**操作效果**
```bash
# 先观察pods情况
kubectl get pods --watch
# 通过tt.yml文件创建或者更新集群
kubectl apply -f tt.yml
# 查看deployments
kubectl get deployments
# 通过label过滤查询
kubectl.exe get deployments -l env=test



# 改动一次replicas的数量，查看rs状态
kubectl get rs
# 发现有多个replicas版本，默认是10个，说明默认自带回退10个版本的功能
# 默认回退上一个版本，指定参数可回退到指定版本，但是不推荐使用！！！！
# 应该用apply应用声明的方式来进行，因为命令式存在重复操作的可能性。而声明式是修改最终状态！！！！
kubectl rollout undo deployment/nginx-deployment --to-revision=2
```


## Job

一次性任务就是job。应用场景：突然有很多的任务堆积，临时加服务消费掉任务。
```yml
apiVersion: batch/v1
kind: Job
metadata:
  name: myjob
  namespace: default
  labels:
    app: myjob
spec:
  # 执行8次这个镜像
  completions: 8
  # 每次可以2个并发
  parallelism: 2
  template:
    metadata:
      name: myjob
      labels:
        app: myjob
    spec:
      containers:
      - name: myjob
        image: ubuntu
        command: ['/bin/sh']
        args:
          - -c
          - echo hello from myjob
      restartPolicy: OnFailure
```

## Cronjob

定时任务就是cronjob。应用场景：日志清理，日常跑批。
```yml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
  namespace: default
spec:
  # 和linux的crontab一致
  schedule: "*/1 * * * *"
  # Pod最长启动或者运行时间
  startingDeadlineSeconds: 10
  # 是否允许并行
  concurrencyPolicy: Allow
  # 允许保留job的历史个数
  successfulJobHistoryLimit: 4
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args: ['/bin/sh', '-c', 'date; echo Hello from the Kubernetes cluster']
          restartPolicy: OnFailure
```

## DaemonSet

在每一个节点或指定节点上运行一个pod服务。应用场景：加入一个新机器需要执行一个骚操作。例如加入rds的白名单。或者node节点自动伸缩，每次拓展的时候推送通知。还有node节点日志收集等内容

```yml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: MYAPP
  namespace: default
  labels:
    app: MYAPP
spec:
  selector:
    matchLabels:
      app: MYAPP
  template:
    metadata:
      labels:
        app: MYAPP
    spec:
      tolerations:
      # 这里的tolerations是在master节点上也要指定。不要的话就删掉它
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: MYAPP
        image: debian
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
      terminationGracePeriodSeconds: 30
```

## 拓展知识

[PSKubectlCompletion](https://github.com/mziyabo/PSKubectlCompletion)：提供powershell的自动补全

```bash
# 声明式，推荐使用
kubectl apply -f test.yml
# 命令式则更适用于job。create是立即干掉pod后执行job
kubectl create -f test.yml
```

## 更新

**20200805**：在deployment新加参数`imagePullPolicy`